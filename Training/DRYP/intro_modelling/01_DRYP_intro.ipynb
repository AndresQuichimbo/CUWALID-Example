{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUWALID TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRYP: Intro to Hydrological modelling with DRYP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This training material is developed to understand all components of the CUWALID modelling system. Each section addresses specific topics tailored to cover all model capabilities and their applications.\n",
    "\n",
    "\n",
    "The first module covers the introduction and understanding of the hydrological model DRYP:\n",
    "\n",
    "1. ***Installation***\n",
    "2. Understanding DRYP gridded model domain\n",
    "3. Understanding DRYP with test models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A detailed description of the installation of CUWALID can be found in:\n",
    "\n",
    "https://cuwalid.github.io/tutorials/#pip-installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the following line will run a series of test that will confirm that the model is working well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the DRYP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuwalid.dryp.main_DRYP import run_DRYP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function run_DRYP in module cuwalid.dryp.main_DRYP:\n",
      "\n",
      "run_DRYP(filename_input)\n",
      "    This function integrates all components of the model, with\n",
      "    all model parameters and component settings being specified in\n",
      "    the -filename_input- file.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(run_DRYP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all model tests\n",
    "from cuwalid.tests.dryp.run_tests import run_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error running test from file: cuwalid.tests.dryp.scripts.test_ponds - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\cuwalid\\tests\\dryp\\run_tests.py\", line 65, in run_tests\n",
      "    test()\n",
      "  File \"C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\cuwalid\\tests\\dryp\\scripts\\test_ponds.py\", line 41, in test_ponds\n",
      "    assert np.allclose(Vo, answer)\n",
      "AssertionError\n",
      "C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\landlab\\graph\\graph.py:403: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  return self.ds.dims[\"node\"]\n",
      "C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\landlab\\graph\\graph.py:490: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  return self.ds.dims[\"link\"]\n",
      "C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\landlab\\graph\\graph.py:869: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  return self.ds.dims[\"patch\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precipitation: Test completed successfully\n",
      "Precipitation read csv: Test completed successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\landlab\\graph\\graph.py:403: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  return self.ds.dims[\"node\"]\n",
      "C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\landlab\\graph\\graph.py:490: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  return self.ds.dims[\"link\"]\n",
      "C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\landlab\\graph\\graph.py:869: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  return self.ds.dims[\"patch\"]\n",
      "C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\landlab\\graph\\graph.py:403: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  return self.ds.dims[\"node\"]\n",
      "C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\landlab\\graph\\graph.py:490: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  return self.ds.dims[\"link\"]\n",
      "C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\landlab\\graph\\graph.py:869: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  return self.ds.dims[\"patch\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precipitation step function: Test completed successfully\n",
      "Infiltration approach: Philips\n",
      "Infiltration: Test completed successfully\n",
      "Soil Layer: Test completed successfully\n",
      "Flow routing: Test completed successfully\n",
      "GW_SW interactions: Test completed successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\landlab\\graph\\graph.py:403: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  return self.ds.dims[\"node\"]\n",
      "C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\landlab\\graph\\graph.py:490: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  return self.ds.dims[\"link\"]\n",
      "C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\landlab\\graph\\graph.py:869: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  return self.ds.dims[\"patch\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS Multi-aquifer:Test completed successfully\n",
      "Groundwater settings: Multi-transmissivity function\n",
      "Groundwater Muti-aquifer: Test completed successfully\n",
      "T Function Groundwater: Test completed successfully\n",
      "Groundwater settings: Linear transmissivity function\n",
      "Groundwater: Test completed successfully\n",
      "Save Dataset: Test completed successfully\n",
      "Save maximum dataset: Test completed successfully\n",
      "Save csv files: Test completed successfully\n",
      "Infiltration approach: Philips\n",
      "Run Interception component\n",
      "Groundwater settings: Linear transmissivity function\n",
      "DRYP model: Test completed successfully\n",
      "\n",
      "reading config file...\n",
      "\n",
      "Warning: 'TERRAIN.path_Qo' set as null. Using default.\n",
      "Warning: 'TERRAIN.path_riv_decay' set as null. Using default.\n",
      "Warning: 'TERRAIN.path_riv_width' set as null. Using default.\n",
      "Warning: 'TERRAIN.path_riv_elev' set as null. Using default.\n",
      "Warning: 'TERRAIN.path_of_bc_flux' was not provided. Using default.\n",
      "Warning: 'VEGETATION.path_veg_kc' set as null. Using default.\n",
      "Warning: 'VEGETATION.path_veg_lulc' set as null. Using default.\n",
      "Warning: 'VEGETATION.path_veg_nn' is not a recognized key and will be ignored.\n",
      "Warning: 'UNSATURATED.path_uz_theta_sat' was not provided. Using default.\n",
      "Warning: 'UNSATURATED.path_uz_rootdepth' was not provided. Using default.\n",
      "Warning: 'UNSATURATED.path_uz_theta' set as null. Using default.\n",
      "Warning: 'UNSATURATED.path_riv_ksat' set as null. Using default.\n",
      "Warning: 'UNSATURATED.path_uz_bottomksat' was not provided. Using default.\n",
      "Warning: 'UNSATURATED.path_uz_bc_flux' was not provided. Using default.\n",
      "Warning: 'UNSATURATED.path_uz_theta_sat: porosity' is not a recognized key and will be ignored.\n",
      "Warning: 'UNSATURATED.path_uz_root' is not a recognized key and will be ignored.\n",
      "Warning: 'SATURATED.path_sz_sy' set as null. Using default.\n",
      "Warning: 'SATURATED.path_sz_bc_flux' set as null. Using default.\n",
      "Warning: 'SATURATED.path_sz_bottom' set as null. Using default.\n",
      "Warning: 'SATURATED.path_sz_depth' was not provided. Using default.\n",
      "Warning: 'SATURATED.path_sz_bdd' was not provided. Using default.\n",
      "Warning: 'SATURATED.path_sz_type' was not provided. Using default.\n",
      "Warning: 'METEO.path_aof' set as null. Using default.\n",
      "Warning: 'METEO.path_lai' was not provided. Using default.\n",
      "Warning: 'METEO.path_savi' was not provided. Using default.\n",
      "Warning: 'METEO.path_kc' was not provided. Using default.\n",
      "Warning: 'METEO.path_TSOF' was not provided. Using default.\n",
      "Warning: 'METEO.path_TSUZ' was not provided. Using default.\n",
      "Warning: 'METEO.path_TSSZ' was not provided. Using default.\n",
      "Warning: 'METEO.path_TSav' was not provided. Using default.\n",
      "Warning: 'METEO.path_TSWB' was not provided. Using default.\n",
      "Warning: 'METEO.Other' is not a recognized key and will be ignored.\n",
      "Warning: 'OUTPUT.path_store_settings' was not provided. Using default.\n",
      "Warning: 'OUTPUT.path_gw_settings' is not a recognized key and will be ignored.\n",
      "Warning: 'OUTPUT.path_vg_settings' is not a recognized key and will be ignored.\n",
      "Warning: 'OUTPUT.path_rp_settings' is not a recognized key and will be ignored.\n",
      "Warning: 'OUTPUT.path_of_settings' is not a recognized key and will be ignored.\n",
      "Warning: 'OUTPUT.path_projection' is not a recognized key and will be ignored.\n",
      "Warning: 'RIPARIAN' was not provided. Using default.\n",
      "Warning: 'INTERCEPTION' was not provided. Using default.\n",
      "Warning: 'GROUNDWATER' was not provided. Using default.\n",
      "Warning: 'WATER_BODIES' was not provided. Using default.\n",
      "\n",
      "Reading settings file...\n",
      "\n",
      "Warning: 'PROJECTION' was not provided. Using default.\n",
      "Warning: 'READING.data_reading.abs' was not provided. Using default.\n",
      "Warning: 'READING.data_reading.kc' was not provided. Using default.\n",
      "Warning: 'READING.data_reading.fluxOF' was not provided. Using default.\n",
      "Warning: 'READING.data_reading.fluxUZ' was not provided. Using default.\n",
      "Warning: 'READING.data_reading.fluxSZ' was not provided. Using default.\n",
      "Warning: 'READING.data_reading.fluxWB' was not provided. Using default.\n",
      "Warning: 'READING.data_reading.savi' was not provided. Using default.\n",
      "Warning: 'READING.data_reading.savi_min' was not provided. Using default.\n",
      "Warning: 'READING.data_reading.savi_max' was not provided. Using default.\n",
      "Warning: 'READING.data_reading.lai' was not provided. Using default.\n",
      "Warning: 'READING.data_reading.av' was not provided. Using default.\n",
      "Warning: 'READING.data_step.abs' was not provided. Using default.\n",
      "Warning: 'READING.data_step.kc' was not provided. Using default.\n",
      "Warning: 'READING.data_step.fluxOF' was not provided. Using default.\n",
      "Warning: 'READING.data_step.fluxUZ' was not provided. Using default.\n",
      "Warning: 'READING.data_step.fluxSZ' was not provided. Using default.\n",
      "Warning: 'READING.data_step.fluxWB' was not provided. Using default.\n",
      "Warning: 'READING.data_step.savi' was not provided. Using default.\n",
      "Warning: 'READING.data_step.savi_min' was not provided. Using default.\n",
      "Warning: 'READING.data_step.savi_max' was not provided. Using default.\n",
      "Warning: 'READING.data_step.lai' was not provided. Using default.\n",
      "Warning: 'READING.data_step.av' was not provided. Using default.\n",
      "Warning: 'READING.data_reproject.abs' was not provided. Using default.\n",
      "Warning: 'READING.data_reproject.kc' was not provided. Using default.\n",
      "Warning: 'READING.data_reproject.fluxOF' was not provided. Using default.\n",
      "Warning: 'READING.data_reproject.fluxUZ' was not provided. Using default.\n",
      "Warning: 'READING.data_reproject.fluxSZ' was not provided. Using default.\n",
      "Warning: 'READING.data_reproject.fluxWB' was not provided. Using default.\n",
      "Warning: 'READING.data_reproject.savi' was not provided. Using default.\n",
      "Warning: 'READING.data_reproject.savi_min' was not provided. Using default.\n",
      "Warning: 'READING.data_reproject.savi_max' was not provided. Using default.\n",
      "Warning: 'READING.data_reproject.lai' was not provided. Using default.\n",
      "Warning: 'READING.data_reproject.av' was not provided. Using default.\n",
      "Warning: 'READING.data_interp.abs' was not provided. Using default.\n",
      "Warning: 'READING.data_interp.kc' was not provided. Using default.\n",
      "Warning: 'READING.data_interp.fluxOF' was not provided. Using default.\n",
      "Warning: 'READING.data_interp.fluxUZ' was not provided. Using default.\n",
      "Warning: 'READING.data_interp.fluxSZ' was not provided. Using default.\n",
      "Warning: 'READING.data_interp.fluxWB' was not provided. Using default.\n",
      "Warning: 'READING.data_interp.savi' was not provided. Using default.\n",
      "Warning: 'READING.data_interp.savi_min' was not provided. Using default.\n",
      "Warning: 'READING.data_interp.savi_max' was not provided. Using default.\n",
      "Warning: 'READING.data_interp.lai' was not provided. Using default.\n",
      "Warning: 'READING.data_interp.av' was not provided. Using default.\n",
      "Warning: 'READING.data_projection' was not provided. Using default.\n",
      "Warning: 'OUTPUT.output_grid_rmax' was not provided. Using default.\n",
      "Warning: 'OUTPUT.output_grid_vmax' was not provided. Using default.\n",
      "Warning: 'OUTPUT.output_dt_csv' was not provided. Using default.\n",
      "Warning: 'OUTPUT.not used 1' is not a recognized key and will be ignored.\n",
      "Warning: 'OUTPUT.Save discharge in volumetric rate units' is not a recognized key and will be ignored.\n",
      "Warning: 'OUTPUT.not used 2' is not a recognized key and will be ignored.\n",
      "Warning: 'OUTPUT.not used 3' is not a recognized key and will be ignored.\n",
      "Warning: 'GLOBAL_FACTORS.uz_kdt' was not provided. Using default.\n",
      "Warning: 'GLOBAL_FACTORS.uz_kdroot' was not provided. Using default.\n",
      "Warning: 'GLOBAL_FACTORS.uz_kawc' was not provided. Using default.\n",
      "Warning: 'GLOBAL_FACTORS.uz_kkast' was not provided. Using default.\n",
      "Warning: 'GLOBAL_FACTORS.uz_ksigma' was not provided. Using default.\n",
      "Warning: 'GLOBAL_FACTORS.riv_kksat' was not provided. Using default.\n",
      "Warning: 'GLOBAL_FACTORS.riv_kdecay' was not provided. Using default.\n",
      "Warning: 'GLOBAL_FACTORS.riv_kwidth' was not provided. Using default.\n",
      "Warning: 'GLOBAL_FACTORS.sz_kksat' was not provided. Using default.\n",
      "Warning: 'GLOBAL_FACTORS.sz_ksy' was not provided. Using default.\n",
      "Warning: 'GLOBAL_FACTORS.of_kflow' was not provided. Using default.\n",
      "Warning: 'GLOBAL_FACTORS.factor_uz_kdt' is not a recognized key and will be ignored.\n",
      "Warning: 'GLOBAL_FACTORS.factor_uz_kdroot' is not a recognized key and will be ignored.\n",
      "Warning: 'GLOBAL_FACTORS.factor_uz_kawc' is not a recognized key and will be ignored.\n",
      "Warning: 'GLOBAL_FACTORS.factor_uz_kkast' is not a recognized key and will be ignored.\n",
      "Warning: 'GLOBAL_FACTORS.factor_uz_ksigma' is not a recognized key and will be ignored.\n",
      "Warning: 'GLOBAL_FACTORS.factor_riv_kksat' is not a recognized key and will be ignored.\n",
      "Warning: 'GLOBAL_FACTORS.factor_riv_kdecay' is not a recognized key and will be ignored.\n",
      "Warning: 'GLOBAL_FACTORS.factor_riv_kwidth' is not a recognized key and will be ignored.\n",
      "Warning: 'GLOBAL_FACTORS.factor_sz_kksat' is not a recognized key and will be ignored.\n",
      "Warning: 'GLOBAL_FACTORS.factor_sz_ksy' is not a recognized key and will be ignored.\n",
      "Warning: 'GLOBAL_FACTORS.factor_of_kflow' is not a recognized key and will be ignored.\n",
      "Store variable option not provided, default parameters applied\n",
      "Model Name:  test\n",
      "********************* Output Directory **********************\n",
      "Directory  tilted_v/output  already exists\n",
      "***************************** READING MODEL PARAMETERS *****************************\n",
      "====== > Reading surface and river network parameters\n",
      "River width......................not provided. Global default applied of W = 10 m\n",
      "River bottom......................not provided\n",
      "River bottom elevation: surface elevation\n",
      "Lake bathymetry..................not provided. Global default z\n",
      "Channel decay parameter..........not provided\n",
      "Assumed value equivalent to a velocity of 1m/s\n",
      "Initial channel storage..........not provided, assumed 0.0 m3\n",
      "====== > Reading hillslope soil hydraulic parameters\n",
      "Porosity.........................not provided. Global default applied of 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\landlab\\graph\\graph.py:403: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  return self.ds.dims[\"node\"]\n",
      "C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\landlab\\graph\\graph.py:490: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  return self.ds.dims[\"link\"]\n",
      "C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\landlab\\graph\\graph.py:869: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  return self.ds.dims[\"patch\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rooting depth....................not provided. Global default applied of 1000mm\n",
      "Initial water content............not provided, dry condition assumed (wiltinf point)\n",
      "====== > Reading riparian soil hydraulic parameters\n",
      "Hydraulic conductivity...........not provided. Global default applied of 1.0 mm/h\n",
      "Wilting point....................not provided. Global default applied of 0.05\n",
      "Porosity.........................not provided. Global default applied of 0.4\n",
      "Available Water Content..........not provided. Global default applied of 0.10\n",
      "Soil particle distribution par...not provided. Global default applied of 10.5\n",
      "Suction head.....................not provided. Global default applied of 153 mm\n",
      "Rooting depth....................not provided. Global default applied of 1000mm\n",
      "Initial water content............not provided, dry condition assumed (wiltinf point)\n",
      "====== > Reading groundwater aquifer hydraulic parameters\n",
      "Transmissivity model type .......not provided\n",
      "Specific yield...................not provided. Global default applied of 0.01\n",
      "Aquifer bottom elevation.........not provided. Global default applied of 0.0 m\n",
      "Aquifer Ksat.....................not provided. Global default applied of 1.0 m/h\n",
      "Flux boundary conditions. .......not provided\n",
      "Constant head boundary conditions not provided\n",
      "Aquifer effective depth..........not provided, aassumed value of 50m\n",
      "====== > Reading interception parameters\n",
      "Fraction of vegetation cover.....not provided. Global default 1\n",
      "Vegetation exponential coef......not provided. Global default 1\n",
      "Vegetation exponential coef......not provided. Global default 1\n",
      "Fraction of vegetation cover.....not provided. Global default 1\n",
      "Fraction of vegetation cover.....not provided. Global default 1\n",
      "Biome-dependent coefficient......not provided. Global 1 [-]\n",
      "Initial canopy storage...........not provided. Global 0 [-]\n",
      "Initial riparian canopy storage, not provided. Global 0 [-]\n",
      "Tap water level..................not provided. Global 0 [mm]\n",
      "Extinction depth.................not provided. Default is rooting depth [mm]\n",
      "====== > Reading water body parameters\n",
      "Water body parameters is not active\n",
      "====== > Reading water body management\n",
      "***************************** READING TEMPORAL DATASETS ****************************\n",
      "====== > Reading precipitation\n",
      "====== > Reading evapoptranspiration\n",
      "====== > Reading vegetation SAVI\n",
      "====== > Reading vegetation LAI\n",
      "====== > Reading vegetation Kc\n",
      "====== > Reading vegetation fraction\n",
      "====== > Reading surface flux boundary conditions\n",
      "Flux dataset.....................not provided\n",
      "====== > Reading unsaturated flux boundary conditions\n",
      "Flux dataset.....................not provided\n",
      "====== > Reading saturated flux boundary conditions\n",
      "Flux dataset.....................not provided\n",
      "====== > Reading reservoirs flux boundary conditions\n",
      "Flux dataset.....................not provided\n",
      "*************************** ASSEMBLING MODEL COMPONENTS ****************************\n",
      "Infiltration approach: Philips\n",
      "Run Interception component\n",
      "Groundwater settings: Constant transmissivity function\n",
      "****************************** SIMULATION IN PROGRESS ******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/733 [00:00<?, ?days/s]C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\landlab\\graph\\graph.py:490: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  return self.ds.dims[\"link\"]\n",
      "C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\landlab\\graph\\graph.py:869: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  return self.ds.dims[\"patch\"]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 733/733 [00:39<00:00, 18.74days/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************** SAVING RESULTS **********************************\n",
      "<==== saving model temporal outputs\n",
      "<==== saving model temporal maximum values at streams outputs\n",
      "<==== saving riparian zone temporal outputs\n",
      "<==== saving water bodies temporal outputs\n",
      "<==== saving raster files for initial conditions\n",
      "======================= ALL PROCESSES COMPLETED SUCCESSFULLY =======================\n",
      "Error running test from file: cuwalid.tests.dryp.scripts.test_dryp_tilted_V - \n",
      "\n",
      "reading config file...\n",
      "\n",
      "Warning: 'TERRAIN.path_Qo' set as null. Using default.\n",
      "Warning: 'TERRAIN.path_riv_decay' set as null. Using default.\n",
      "Warning: 'TERRAIN.path_riv_width' set as null. Using default.\n",
      "Warning: 'TERRAIN.path_riv_elev' set as null. Using default.\n",
      "Warning: 'TERRAIN.path_of_bc_flux' was not provided. Using default.\n",
      "Warning: 'VEGETATION.path_veg_kc' set as null. Using default.\n",
      "Warning: 'VEGETATION.path_veg_lulc' set as null. Using default.\n",
      "Warning: 'VEGETATION.path_veg_nn' is not a recognized key and will be ignored.\n",
      "Warning: 'UNSATURATED.path_uz_theta_sat' was not provided. Using default.\n",
      "Warning: 'UNSATURATED.path_uz_rootdepth' was not provided. Using default.\n",
      "Warning: 'UNSATURATED.path_uz_theta' set as null. Using default.\n",
      "Warning: 'UNSATURATED.path_riv_ksat' set as null. Using default.\n",
      "Warning: 'UNSATURATED.path_uz_bottomksat' was not provided. Using default.\n",
      "Warning: 'UNSATURATED.path_uz_bc_flux' was not provided. Using default.\n",
      "Warning: 'UNSATURATED.path_uz_theta_sat: porosity' is not a recognized key and will be ignored.\n",
      "Warning: 'UNSATURATED.path_uz_root' is not a recognized key and will be ignored.\n",
      "Warning: 'SATURATED.path_sz_sy' set as null. Using default.\n",
      "Warning: 'SATURATED.path_sz_bc_flux' set as null. Using default.\n",
      "Warning: 'SATURATED.path_sz_bottom' set as null. Using default.\n",
      "Warning: 'SATURATED.path_sz_depth' was not provided. Using default.\n",
      "Warning: 'SATURATED.path_sz_bdd' was not provided. Using default.\n",
      "Warning: 'SATURATED.path_sz_type' was not provided. Using default.\n",
      "Warning: 'METEO.path_aof' set as null. Using default.\n",
      "Warning: 'METEO.path_lai' was not provided. Using default.\n",
      "Warning: 'METEO.path_savi' was not provided. Using default.\n",
      "Warning: 'METEO.path_kc' was not provided. Using default.\n",
      "Warning: 'METEO.path_TSOF' was not provided. Using default.\n",
      "Warning: 'METEO.path_TSUZ' was not provided. Using default.\n",
      "Warning: 'METEO.path_TSSZ' was not provided. Using default.\n",
      "Warning: 'METEO.path_TSav' was not provided. Using default.\n",
      "Warning: 'METEO.path_TSWB' was not provided. Using default.\n",
      "Warning: 'METEO.Other' is not a recognized key and will be ignored.\n",
      "Warning: 'OUTPUT.path_store_settings' was not provided. Using default.\n",
      "Warning: 'OUTPUT.path_gw_settings' is not a recognized key and will be ignored.\n",
      "Warning: 'OUTPUT.path_vg_settings' is not a recognized key and will be ignored.\n",
      "Warning: 'OUTPUT.path_rp_settings' is not a recognized key and will be ignored.\n",
      "Warning: 'OUTPUT.path_of_settings' is not a recognized key and will be ignored.\n",
      "Warning: 'OUTPUT.path_projection' is not a recognized key and will be ignored.\n",
      "Warning: 'RIPARIAN' was not provided. Using default.\n",
      "Warning: 'INTERCEPTION' was not provided. Using default.\n",
      "Warning: 'GROUNDWATER' was not provided. Using default.\n",
      "Warning: 'WATER_BODIES' was not provided. Using default.\n",
      "\n",
      "Reading settings file...\n",
      "\n",
      "Warning: 'PROJECTION' was not provided. Using default.\n",
      "Warning: 'READING.data_reading.abs' was not provided. Using default.\n",
      "Warning: 'READING.data_reading.kc' was not provided. Using default.\n",
      "Warning: 'READING.data_reading.fluxOF' was not provided. Using default.\n",
      "Warning: 'READING.data_reading.fluxUZ' was not provided. Using default.\n",
      "Warning: 'READING.data_reading.fluxSZ' was not provided. Using default.\n",
      "Warning: 'READING.data_reading.fluxWB' was not provided. Using default.\n",
      "Warning: 'READING.data_reading.savi' was not provided. Using default.\n",
      "Warning: 'READING.data_reading.savi_min' was not provided. Using default.\n",
      "Warning: 'READING.data_reading.savi_max' was not provided. Using default.\n",
      "Warning: 'READING.data_reading.lai' was not provided. Using default.\n",
      "Warning: 'READING.data_reading.av' was not provided. Using default.\n",
      "Warning: 'READING.data_step.abs' was not provided. Using default.\n",
      "Warning: 'READING.data_step.kc' was not provided. Using default.\n",
      "Warning: 'READING.data_step.fluxOF' was not provided. Using default.\n",
      "Warning: 'READING.data_step.fluxUZ' was not provided. Using default.\n",
      "Warning: 'READING.data_step.fluxSZ' was not provided. Using default.\n",
      "Warning: 'READING.data_step.fluxWB' was not provided. Using default.\n",
      "Warning: 'READING.data_step.savi' was not provided. Using default.\n",
      "Warning: 'READING.data_step.savi_min' was not provided. Using default.\n",
      "Warning: 'READING.data_step.savi_max' was not provided. Using default.\n",
      "Warning: 'READING.data_step.lai' was not provided. Using default.\n",
      "Warning: 'READING.data_step.av' was not provided. Using default.\n",
      "Warning: 'READING.data_reproject.abs' was not provided. Using default.\n",
      "Warning: 'READING.data_reproject.kc' was not provided. Using default.\n",
      "Warning: 'READING.data_reproject.fluxOF' was not provided. Using default.\n",
      "Warning: 'READING.data_reproject.fluxUZ' was not provided. Using default.\n",
      "Warning: 'READING.data_reproject.fluxSZ' was not provided. Using default.\n",
      "Warning: 'READING.data_reproject.fluxWB' was not provided. Using default.\n",
      "Warning: 'READING.data_reproject.savi' was not provided. Using default.\n",
      "Warning: 'READING.data_reproject.savi_min' was not provided. Using default.\n",
      "Warning: 'READING.data_reproject.savi_max' was not provided. Using default.\n",
      "Warning: 'READING.data_reproject.lai' was not provided. Using default.\n",
      "Warning: 'READING.data_reproject.av' was not provided. Using default.\n",
      "Warning: 'READING.data_interp.abs' was not provided. Using default.\n",
      "Warning: 'READING.data_interp.kc' was not provided. Using default.\n",
      "Warning: 'READING.data_interp.fluxOF' was not provided. Using default.\n",
      "Warning: 'READING.data_interp.fluxUZ' was not provided. Using default.\n",
      "Warning: 'READING.data_interp.fluxSZ' was not provided. Using default.\n",
      "Warning: 'READING.data_interp.fluxWB' was not provided. Using default.\n",
      "Warning: 'READING.data_interp.savi' was not provided. Using default.\n",
      "Warning: 'READING.data_interp.savi_min' was not provided. Using default.\n",
      "Warning: 'READING.data_interp.savi_max' was not provided. Using default.\n",
      "Warning: 'READING.data_interp.lai' was not provided. Using default.\n",
      "Warning: 'READING.data_interp.av' was not provided. Using default.\n",
      "Warning: 'READING.data_projection' was not provided. Using default.\n",
      "Warning: 'OUTPUT.output_grid_rmax' was not provided. Using default.\n",
      "Warning: 'OUTPUT.output_grid_vmax' was not provided. Using default.\n",
      "Warning: 'OUTPUT.output_dt_csv' was not provided. Using default.\n",
      "Warning: 'OUTPUT.not used 1' is not a recognized key and will be ignored.\n",
      "Warning: 'OUTPUT.Save discharge in volumetric rate units' is not a recognized key and will be ignored.\n",
      "Warning: 'OUTPUT.not used 2' is not a recognized key and will be ignored.\n",
      "Warning: 'OUTPUT.not used 3' is not a recognized key and will be ignored.\n",
      "Warning: 'GLOBAL_FACTORS.uz_kdt' was not provided. Using default.\n",
      "Warning: 'GLOBAL_FACTORS.uz_kdroot' was not provided. Using default.\n",
      "Warning: 'GLOBAL_FACTORS.uz_kawc' was not provided. Using default.\n",
      "Warning: 'GLOBAL_FACTORS.uz_kkast' was not provided. Using default.\n",
      "Warning: 'GLOBAL_FACTORS.uz_ksigma' was not provided. Using default.\n",
      "Warning: 'GLOBAL_FACTORS.riv_kksat' was not provided. Using default.\n",
      "Warning: 'GLOBAL_FACTORS.riv_kdecay' was not provided. Using default.\n",
      "Warning: 'GLOBAL_FACTORS.riv_kwidth' was not provided. Using default.\n",
      "Warning: 'GLOBAL_FACTORS.sz_kksat' was not provided. Using default.\n",
      "Warning: 'GLOBAL_FACTORS.sz_ksy' was not provided. Using default.\n",
      "Warning: 'GLOBAL_FACTORS.of_kflow' was not provided. Using default.\n",
      "Warning: 'GLOBAL_FACTORS.factor_uz_kdt' is not a recognized key and will be ignored.\n",
      "Warning: 'GLOBAL_FACTORS.factor_uz_kdroot' is not a recognized key and will be ignored.\n",
      "Warning: 'GLOBAL_FACTORS.factor_uz_kawc' is not a recognized key and will be ignored.\n",
      "Warning: 'GLOBAL_FACTORS.factor_uz_kkast' is not a recognized key and will be ignored.\n",
      "Warning: 'GLOBAL_FACTORS.factor_uz_ksigma' is not a recognized key and will be ignored.\n",
      "Warning: 'GLOBAL_FACTORS.factor_riv_kksat' is not a recognized key and will be ignored.\n",
      "Warning: 'GLOBAL_FACTORS.factor_riv_kdecay' is not a recognized key and will be ignored.\n",
      "Warning: 'GLOBAL_FACTORS.factor_riv_kwidth' is not a recognized key and will be ignored.\n",
      "Warning: 'GLOBAL_FACTORS.factor_sz_kksat' is not a recognized key and will be ignored.\n",
      "Warning: 'GLOBAL_FACTORS.factor_sz_ksy' is not a recognized key and will be ignored.\n",
      "Warning: 'GLOBAL_FACTORS.factor_of_kflow' is not a recognized key and will be ignored.\n",
      "Store variable option not provided, default parameters applied\n",
      "Model Name:  test\n",
      "********************* Output Directory **********************\n",
      "Directory  tilted_v/output  already exists\n",
      "***************************** READING MODEL PARAMETERS *****************************\n",
      "====== > Reading surface and river network parameters\n",
      "River width......................not provided. Global default applied of W = 10 m\n",
      "River bottom......................not provided\n",
      "River bottom elevation: surface elevation\n",
      "Lake bathymetry..................not provided. Global default z\n",
      "Channel decay parameter..........not provided\n",
      "Assumed value equivalent to a velocity of 1m/s\n",
      "Initial channel storage..........not provided, assumed 0.0 m3\n",
      "====== > Reading hillslope soil hydraulic parameters\n",
      "Porosity.........................not provided. Global default applied of 0.4\n",
      "Rooting depth....................not provided. Global default applied of 1000mm\n",
      "Initial water content............not provided, dry condition assumed (wiltinf point)\n",
      "====== > Reading riparian soil hydraulic parameters\n",
      "Hydraulic conductivity...........not provided. Global default applied of 1.0 mm/h\n",
      "Wilting point....................not provided. Global default applied of 0.05\n",
      "Porosity.........................not provided. Global default applied of 0.4\n",
      "Available Water Content..........not provided. Global default applied of 0.10\n",
      "Soil particle distribution par...not provided. Global default applied of 10.5\n",
      "Suction head.....................not provided. Global default applied of 153 mm\n",
      "Rooting depth....................not provided. Global default applied of 1000mm\n",
      "Initial water content............not provided, dry condition assumed (wiltinf point)\n",
      "====== > Reading groundwater aquifer hydraulic parameters\n",
      "Transmissivity model type .......not provided\n",
      "Specific yield...................not provided. Global default applied of 0.01\n",
      "Aquifer bottom elevation.........not provided. Global default applied of 0.0 m\n",
      "Aquifer Ksat.....................not provided. Global default applied of 1.0 m/h\n",
      "Flux boundary conditions. .......not provided\n",
      "Constant head boundary conditions not provided\n",
      "Aquifer effective depth..........not provided, aassumed value of 50m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\cuwalid\\tests\\dryp\\run_tests.py\", line 65, in run_tests\n",
      "    test()\n",
      "  File \"C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\cuwalid\\tests\\dryp\\scripts\\test_dryp_tilted_V.py\", line 38, in test_dryp\n",
      "    assert np.allclose(out, ans)\n",
      "AssertionError\n",
      "C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\landlab\\graph\\graph.py:403: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  return self.ds.dims[\"node\"]\n",
      "C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\landlab\\graph\\graph.py:490: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  return self.ds.dims[\"link\"]\n",
      "C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\landlab\\graph\\graph.py:869: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  return self.ds.dims[\"patch\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== > Reading interception parameters\n",
      "Fraction of vegetation cover.....not provided. Global default 1\n",
      "Vegetation exponential coef......not provided. Global default 1\n",
      "Vegetation exponential coef......not provided. Global default 1\n",
      "Fraction of vegetation cover.....not provided. Global default 1\n",
      "Fraction of vegetation cover.....not provided. Global default 1\n",
      "Biome-dependent coefficient......not provided. Global 1 [-]\n",
      "Initial canopy storage...........not provided. Global 0 [-]\n",
      "Initial riparian canopy storage, not provided. Global 0 [-]\n",
      "Tap water level..................not provided. Global 0 [mm]\n",
      "Extinction depth.................not provided. Default is rooting depth [mm]\n",
      "====== > Reading water body parameters\n",
      "Water body parameters is not active\n",
      "====== > Reading water body management\n",
      "***************************** READING TEMPORAL DATASETS ****************************\n",
      "====== > Reading precipitation\n",
      "====== > Reading evapoptranspiration\n",
      "====== > Reading vegetation SAVI\n",
      "====== > Reading vegetation LAI\n",
      "====== > Reading vegetation Kc\n",
      "====== > Reading vegetation fraction\n",
      "====== > Reading surface flux boundary conditions\n",
      "Flux dataset.....................not provided\n",
      "====== > Reading unsaturated flux boundary conditions\n",
      "Flux dataset.....................not provided\n",
      "====== > Reading saturated flux boundary conditions\n",
      "Flux dataset.....................not provided\n",
      "====== > Reading reservoirs flux boundary conditions\n",
      "Flux dataset.....................not provided\n",
      "*************************** ASSEMBLING MODEL COMPONENTS ****************************\n",
      "Infiltration approach: Philips\n",
      "Run Interception component\n",
      "Groundwater settings: Constant transmissivity function\n",
      "****************************** SIMULATION IN PROGRESS ******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/733 [00:00<?, ?days/s]C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\landlab\\graph\\graph.py:490: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  return self.ds.dims[\"link\"]\n",
      "C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\landlab\\graph\\graph.py:869: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  return self.ds.dims[\"patch\"]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 733/733 [00:38<00:00, 18.93days/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************** SAVING RESULTS **********************************\n",
      "<==== saving model temporal outputs\n",
      "<==== saving model temporal maximum values at streams outputs\n",
      "<==== saving riparian zone temporal outputs\n",
      "<==== saving water bodies temporal outputs\n",
      "<==== saving raster files for initial conditions\n",
      "======================= ALL PROCESSES COMPLETED SUCCESSFULLY =======================\n",
      "Error running test from file: cuwalid.tests.dryp.scripts.test_dryp - operands could not be broadcast together with shapes (17591,) (25,) \n",
      "Basin delineation: Test completed successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\cuwalid\\tests\\dryp\\run_tests.py\", line 65, in run_tests\n",
      "    test()\n",
      "  File \"C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\cuwalid\\tests\\dryp\\scripts\\test_dryp.py\", line 28, in test_dryp\n",
      "    assert np.allclose(out, ans)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\numpy\\core\\numeric.py\", line 2241, in allclose\n",
      "    res = all(isclose(a, b, rtol=rtol, atol=atol, equal_nan=equal_nan))\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\numpy\\core\\numeric.py\", line 2351, in isclose\n",
      "    return within_tol(x, y, atol, rtol)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\numpy\\core\\numeric.py\", line 2332, in within_tol\n",
      "    return less_equal(abs(x-y), atol + rtol * abs(y))\n",
      "                          ~^~\n",
      "ValueError: operands could not be broadcast together with shapes (17591,) (25,) \n",
      "C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\landlab\\graph\\graph.py:403: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  return self.ds.dims[\"node\"]\n",
      "C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\landlab\\graph\\graph.py:490: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  return self.ds.dims[\"link\"]\n",
      "C:\\Users\\Edisson\\.conda\\envs\\tdryp\\Lib\\site-packages\\landlab\\graph\\graph.py:869: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  return self.ds.dims[\"patch\"]\n"
     ]
    }
   ],
   "source": [
    "# call the function run all tests\n",
    "run_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRYP modelling tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the preprocessing component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cuwalid.dryp.components.DRYP_watershed as ppbasin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module cuwalid.dryp.components.DRYP_watershed in cuwalid.dryp.components:\n",
      "\n",
      "NAME\n",
      "    cuwalid.dryp.components.DRYP_watershed - DRYP: Calculate catchment areas at poin location\n",
      "\n",
      "FUNCTIONS\n",
      "    get_flow_path(fname_surface, fname_outlet, fname_out=None, fname_flowDir=None, fname_mask=None, accum=True)\n",
      "        This function read the input dataset file and\n",
      "        calculate the area and indices (in landlab format). It also\n",
      "        provides a map of contributing areas (flow accumulation).\n",
      "        \n",
      "        This function store all files in the same directory of the\n",
      "        output files if post processing directory is not provided.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        fname_surface: str\n",
      "                file name of the elevation raster map\n",
      "        fname_outlet : str\n",
      "                file name of the outflow raster map\n",
      "        fname_floedir : str\n",
      "                (optional) filename of the flow direction raster map\n",
      "        fname_out : str\n",
      "                (optional) filename of the output raster file\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        file\n",
      "                csv file containing a list areas and node index\n",
      "                asc flow accumalation map as raster file\n",
      "        \n",
      "                \n",
      "        Examples\n",
      "        --------\n",
      "        \n",
      "        >>> from cuwalid.dryp.components.DRYP_watershed import get_watershed_map\n",
      "        >>> fname_surface = \"surface.asc\"\n",
      "        >>> fname_flowdir = \"flowdir.asc\"\n",
      "        >>> fname_outlet = \"point.csv\"\n",
      "        \n",
      "        >>> get_watershed_area(fname_surface, fname_outlet, fname_flowdir)\n",
      "    \n",
      "    get_raster_properties(fname)\n",
      "    \n",
      "    get_watershed_area(fname_surface, fname_outlet, fname_out=None, fname_flowDir=None, fname_mask=None)\n",
      "        This function read the input dataset file and\n",
      "        calculate the area and indices (in landlab format). It also\n",
      "        provides a map of contributing areas (flow accumulation).\n",
      "        \n",
      "        This function store all files in the same directory of the\n",
      "        output files if post processing directory is not provided.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        fname_surface: str\n",
      "                file name of the elevation raster map\n",
      "        fname_outlet : str\n",
      "                file name of the outflow raster map\n",
      "        fname_floedir : str\n",
      "                (optional) filename of the flow direction raster map\n",
      "        fname_out : str\n",
      "                (optional) filename of the output raster file\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        file\n",
      "                csv file containing a list areas and node index\n",
      "                asc flow accumalation map as raster file\n",
      "        \n",
      "                \n",
      "        Examples\n",
      "        --------\n",
      "        \n",
      "        >>> from cuwalid.dryp.components.DRYP_watershed import get_watershed_map\n",
      "        >>> fname_surface = \"surface.asc\"\n",
      "        >>> fname_flowdir = \"flowdir.asc\"\n",
      "        >>> fname_outlet = \"point.csv\"\n",
      "        \n",
      "        >>> get_watershed_area(fname_surface, fname_outlet, fname_flowdir)\n",
      "    \n",
      "    get_watershed_mask(fname_surface, fname_outlet, fname_out=None, fname_flowDir=None, fname_mask=None, raster=False)\n",
      "        Function to delineate a basin assuming an outlet\n",
      "        point is provided. This function requires a flow direction map\n",
      "        but if not provided the flow direction will be created\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        fname_surface: str\n",
      "                file name of the elevation raster map\n",
      "        fname_outlet : str\n",
      "                file name of the outflow raster map\n",
      "        fname_floedir : str\n",
      "                (optional) filename of the flow direction raster map\n",
      "        fname_out : str\n",
      "                (optional) filename of the output raster file\n",
      "        raster: bool\n",
      "                value that specify if it is a raster or csv fname_outlet\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        raster file\n",
      "        \n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from cuwalid.dryp.components.DRYP_watershed import get_watershed_map\n",
      "        >>> fname_surface = \"surface.asc\"\n",
      "        >>> fname_flowdir = \"flowdir.asc\"\n",
      "        >>> fname_outlet = \"point.csv\"\n",
      "        >>> get_watershed_mask(fname_surface, fname_outlet, fname_flowdir)\n",
      "    \n",
      "    open_raster(fname)\n",
      "    \n",
      "    read_raster(fname)\n",
      "    \n",
      "    save_raster(fname, data, profile, transform)\n",
      "\n",
      "FILE\n",
      "    c:\\users\\edisson\\.conda\\envs\\tdryp\\lib\\site-packages\\cuwalid\\dryp\\components\\dryp_watershed.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ppbasin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calling the preprocessing tool**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import raster preprocessing tool\n",
    "import cuwalid.tools.DRYP_rrtools as rrtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module cuwalid.tools.DRYP_rrtools in cuwalid.tools:\n",
      "\n",
      "NAME\n",
      "    cuwalid.tools.DRYP_rrtools - DRYP raster pre-processing tools\n",
      "\n",
      "FUNCTIONS\n",
      "    calculate_channel_residence_time(velocity, river_length)\n",
      "        Calculate decay parameter from streamflow velocity and river length\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        velocity : numpy array of floats\n",
      "                river flow velocity in m3 s-1\n",
      "        river_length : numpy array of floats\n",
      "                river length in meters\n",
      "                \n",
      "        Returns\n",
      "        -------\n",
      "        decay : numpy array floats\n",
      "                channel decay/residence time parameter\n",
      "    \n",
      "    calculate_channel_velocity(discharge, width, slope=0.01, roughness=0.026)\n",
      "        Calculate channel valocity\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        discharge : numpy array of floats\n",
      "                discharge in m3 s-1\n",
      "        width : numpy array or float\n",
      "                channel width in meters\n",
      "                \n",
      "        Returns\n",
      "        -------\n",
      "        numpy array\n",
      "                channel streamflow velocity in m3 s-1\n",
      "    \n",
      "    calculate_channel_width_from_discharge(discharge)\n",
      "        This function estimates channel velocity from flow rate\n",
      "        using the\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        discharge : numpy array of floats\n",
      "                discharge in m3 s-1\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        width : numpy array of floats\n",
      "                channel width\n",
      "    \n",
      "    calculate_soil_paramters(porosity, psi, lambdas, psi_fc=336.506, psi_wp=15295.743)\n",
      "        This function calculate the water content at\n",
      "        field capacity and the total availble water of the soli\n",
      "        from Clapp and Horner\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        porosity : float or numpy array\n",
      "                porosity [-]\n",
      "        psi : float or numpy array\n",
      "                air entry pressure [cm]\n",
      "        lambdas : float or numpy array\n",
      "                soil particle distribution paramters\n",
      "        phi_fc : float or numpy array\n",
      "                suction head at field capacity [cm]\n",
      "                default, phi_fc = 336.506 #cm => 33kPa\n",
      "        phi_wp : float or numpy array\n",
      "                suction head at wilting point [cm],\n",
      "                default, phi_wp = 15295.743 # cm => 1500kPa\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        field_capacity : float or numpy array\n",
      "                water content at field capacity [-]\n",
      "        wilting_point : float or numpy array\n",
      "                Water content at wilting point [-]\n",
      "        available_water_content : float or numpy array\n",
      "                availble water content,  storage capacity [-]\n",
      "    \n",
      "    check_raster_alignaments(fname_base, fname)\n",
      "        This function check if a rasters dataset has the same\n",
      "        number of cells and grid size\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        fname_base : str\n",
      "                file name of the reference raster\n",
      "        fname : str\n",
      "                file name of the raster to check\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        bool\n",
      "                True if raster has similar size\n",
      "                False if raster does not match the original size\n",
      "    \n",
      "    clapp_horner_retention_curve(ipsi, porosity, psi, lambdas)\n",
      "        Function to estimate water content at specied matric\n",
      "        potentialClap and Horn water retention curve\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        ipsi : float or numpy array\n",
      "                matrix potential\n",
      "        porosity : numpy array of floats\n",
      "                water content at saturated conditions\n",
      "        psi : numpy array of float\n",
      "                soil ari entry pressure\n",
      "        lambdas : numpy array of floats\n",
      "                soil particle distribution\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        theta : numpy array of floats\n",
      "                water content at the\n",
      "    \n",
      "    clip_raster_by_extent(fname, fname_output, extent)\n",
      "        Function to clip raster files by extent.\n",
      "        \n",
      "        Parameters\n",
      "        ----------    \n",
      "        fname : str\n",
      "                raster file name\n",
      "        fname_out : str\n",
      "                file name for the clipped raster dataset\n",
      "        extent : list of floats\n",
      "                list of boundaries to clip, [xmin, ymin, xmax, ymax]\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        file\n",
      "                clipped raster file\n",
      "    \n",
      "    clip_raster_by_mask(fname, fname_mask, fname_output)\n",
      "        This function clip a raster file by using a mask raster file. All raster\n",
      "        files must have the same size, otherwise and error will raise.\n",
      "        The output file will be \n",
      "        \n",
      "        Parameters\n",
      "        ----------    \n",
      "        fname : str\n",
      "                raster file name\n",
      "        fname_mask : str\n",
      "                file name for the clipped raster dataset\n",
      "        fname_out : str\n",
      "                file name for the clipped raster dataset\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        file\n",
      "                clipped raster file\n",
      "    \n",
      "    create_raster_bc_at_point(fname_wte, fname_bc_head, fname_out)\n",
      "        Create a raster file from values at specified locations\n",
      "        of a raster file. Only values at selcted locations are kept in\n",
      "        the raster, the remained values are assined -9999\n",
      "        (non data values in DRYP).\n",
      "        \n",
      "        Parameters:\n",
      "        ----------\n",
      "        fname_wte : str\n",
      "                file path of the raster file\n",
      "                The raster file should be in a format supported by rasterio (e.g., GeoTIFF).\n",
      "                The raster file should contain the values that you want to extract at the specified locations.\n",
      "                For example, if you have a raster file representing water table elevation, provide the path to that file.\n",
      "                Make sure to provide the correct file path to the raster file.\n",
      "                Example: \"path/to/raster_file.tif\"\n",
      "        fname_bc_head : str\n",
      "                file path of the point list\n",
      "                coordinates of the points to be extracted from the raster\n",
      "                are specified in the file. The file must contain two columns:\n",
      "                'East' and 'North', which represent the coordinates of the points.\n",
      "                These coordinates should be in the same coordinate system as the raster file.\n",
      "                For example, if the raster file is in UTM coordinates, the coordinates in the file should also be in UTM.\n",
      "                Make sure to provide the correct file path to the point list.\n",
      "                Example: \"path/to/point_list.csv\"\n",
      "        fname_out : str\n",
      "                file path of the output raster file\n",
      "                The output raster file will be created with the specified name.\n",
      "                The output raster file will contain the values at the specified locations.\n",
      "                Make sure to provide the correct file path and name for the output raster file.\n",
      "                Example: \"path/to/output_raster.tif\"\n",
      "                Note: The output raster file will be created in the same format as the input raster file.\n",
      "        \n",
      "        Returns:\n",
      "        -------\n",
      "        None\n",
      "                None, but creates a raster file with the specified name.\n",
      "                The raster file will contain the values at the specified locations.\n",
      "                Note: The function does not return any values, but it saves the\n",
      "                raster file with the specified name.\n",
      "        \n",
      "        Example:\n",
      "        -------\n",
      "        >>> fname_wte = \"water_table_elevation.asc\"\n",
      "        >>> fname_bc_head = \"boundary_conditions.csv\"\n",
      "        >>> fname_out = \"boundary_conditions_raster.asc\"\n",
      "        >>> create_raster_bc_at_point(fname_wte, fname_bc_head, fname_out)\n",
      "        >>> # This will create a raster file named \"boundary_conditions_raster.asc\"\n",
      "        >>> # with the values at the specified locations.\n",
      "        >>> # The function does not return any values, but it saves the raster file.\n",
      "    \n",
      "    create_raster_flowdirection_dryp(fname, fname_out, translate=True)\n",
      "        Create raster file from a raster D8 flow direction map\n",
      "        \n",
      "        Parameters:\n",
      "        ----------\n",
      "        fname : str\n",
      "                filename path of the flow direction map, the raster\n",
      "                file has to be in D8 direction format\n",
      "        fname_out : str\n",
      "                filename of the output file\n",
      "        \n",
      "        Returns:\n",
      "        -------\n",
      "        None\n",
      "                None, but creates a raster file with the specified name.\n",
      "                The raster file will contain the flow direction values in Landlab format.\n",
      "                Note: The function does not return any values, but it saves the\n",
      "                raster file with the specified name.\n",
      "        \n",
      "        Example:\n",
      "        -------\n",
      "        >>> fname = \"flow_direction.asc\n",
      "        >>> fname_out = \"flow_direction_landlab.asc\n",
      "        >>> create_raster_flowdirection_dryp(fname, fname_out, translate=True)\n",
      "        >>> # This will create a raster file named \"flow_direction_landlab.asc\"\n",
      "        >>> # with the flow direction values in Landlab format.\n",
      "        >>> # The function does not return any values, but it saves the raster file.\n",
      "    \n",
      "    create_raster_from_shapefile(fname_shp, fname_raster, fname_out)\n",
      "        This function takes a shapefile (\\*.shp) and a raster file\n",
      "        to create a new raster containing the shapefile geometry\n",
      "        as mask\n",
      "        \n",
      "        Parameters:\n",
      "        ----------\n",
      "        fname_shp : str\n",
      "                file path of shapefile\n",
      "        fname_raster : str\n",
      "                file path of raster file\n",
      "        \n",
      "        Returns:\n",
      "        -------\n",
      "        None\n",
      "                None, but creates a raster file with the specified name.\n",
      "                The raster file will contain the shapefile geometry as a mask.\n",
      "                Note: The function does not return any values, but it saves the\n",
      "                raster file with the specified name.\n",
      "        \n",
      "        Example\n",
      "        -------\n",
      "        \n",
      "        >>> shapefile_path = 'test.shp'\n",
      "        >>> fname_raster = \"test.asc\"\n",
      "        >>> fname_out = \"mask.asc\"\n",
      "        >>> create_raster_from_shapefile(shapefile_path, fname_raster, fname_out)\n",
      "        >>> # This will create a raster file named \"mask.asc\"\n",
      "        >>> # with the shapefile geometry as a mask.\n",
      "        >>> # The function does not return any values, but it saves the raster file.\n",
      "    \n",
      "    create_raster_landlab_idcorenodes(fname, fname_out)\n",
      "        Create a raster file of landlab idnodes\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        fname : str\n",
      "                path of mask raster file\n",
      "                \n",
      "        Returns\n",
      "        -------\n",
      "        file\n",
      "                idnodes raster file with name fname_out\n",
      "    \n",
      "    create_raster_landlab_idnodes(fname, fname_out)\n",
      "        Create a raster file of landlab idnodes\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        fname : str\n",
      "                path of raster file\n",
      "                \n",
      "        Returns:\n",
      "        -------\n",
      "        None\n",
      "                None, but creates a raster file with the specified name.\n",
      "                The raster file will contain the idnodes values in Landlab format.\n",
      "                Note: The function does not return any values, but it saves the\n",
      "                raster file with the specified name.\n",
      "        \n",
      "        Example:\n",
      "        -------\n",
      "        \n",
      "        >>> fname = \"raster.asc\"\n",
      "        >>> fname_out = \"idnodes.asc\"\n",
      "        >>> create_raster_landlab_idnodes(fname, fname_out)\n",
      "        >>> # This will create a raster file named \"idnodes.asc\"\n",
      "        >>> # with the idnodes values in Landlab format.\n",
      "        >>> # The function does not return any values, but it saves the raster file.\n",
      "    \n",
      "    create_raster_river_network(fname, threshold, fname_out, cell_area=False, fill_value=None)\n",
      "        Create a raster file from a raster D8 flow direction map. The\n",
      "        river network will be created from a flow accumulation map and a \n",
      "        threshold specified for the minimm number of cells or minimum area.\n",
      "        \n",
      "        Parameters:\n",
      "        ----------\n",
      "        fname : str\n",
      "                filename path of the flow accumulation map, this file raster\n",
      "                file can be created by get_watershed_area() funtion\n",
      "        threshold : float\n",
      "                number of cells otr area (if cell_area is False)\n",
      "        fname_out : str\n",
      "                filename of the output file\n",
      "        cell_area : Bool\n",
      "                False when area is provided, True when number of cell is\n",
      "                provided\n",
      "        fill_value : float\n",
      "                river lenght [meters]\n",
      "        \n",
      "        Returns:\n",
      "        --------\n",
      "        None\n",
      "                None, but creates a raster file with the specified name.\n",
      "                The raster file will contain the river network values in Landlab format.\n",
      "                Note: The function does not return any values, but it saves the\n",
      "                raster file with the specified name.\n",
      "        \n",
      "        Example:\n",
      "        -------\n",
      "        \n",
      "        >>> fname = \"flow_accumulation.asc\"\n",
      "        >>> threshold = 1000    # number of cells or area in square meters\n",
      "        >>> fname_out = \"river_network.asc\"\n",
      "        >>> create_raster_river_network(fname, threshold, fname_out, cell_area=False, fill_value=None)\n",
      "        >>> # This will create a raster file named \"river_network.asc\"\n",
      "        >>> # with the river network values in Landlab format.\n",
      "        >>> # The function does not return any values, but it saves the raster file.\n",
      "    \n",
      "    create_raster_soil_parameters(fname_porosity, fname_psi, fname_lambda)\n",
      "        Calculate soil water content at field capacity and available water content\n",
      "        \n",
      "        Parameters:\n",
      "        ----------\n",
      "        fname_porosity : str\n",
      "                raster file name of porosity\n",
      "        fname_psi : str\n",
      "                raster filename of air entry pressure\n",
      "        fname_lambda : str\n",
      "                raster file name of soil particle distribution\n",
      "        \n",
      "        Returns:\n",
      "        --------\n",
      "        None\n",
      "                None, but creates three raster files with the following names:\n",
      "        \n",
      "        Examples:\n",
      "        --------\n",
      "        >>> fname_porosity = \"porosity.asc\"\n",
      "        >>> fname_psi = \"psi.asc\"\n",
      "        >>> fname_lambda = \"lambda.asc\"\n",
      "        >>> create_raster_soil_parameters(fname_porosity, fname_psi, fname_lambda)\n",
      "        >>> # This will create three raster files: \"field_capacity.asc\", \"wilting_point.asc\", and \"available_water_content.asc\"\n",
      "        >>> # with the calculated soil water content values.\n",
      "        >>> # The function does not return any values, but it saves the results as raster files.\n",
      "    \n",
      "    find_indices(raster, coordinates)\n",
      "        Finds the indices of the points in the raster given the coordinates.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        dataset: rasterio dataset object\n",
      "                Dataset object.\n",
      "        coordinates: list\n",
      "                A list of tuples containing the (x, y) coordinates of the points.\n",
      "        Returns\n",
      "        -------\n",
      "          A list of tuples containing the (row, column) indices of the points.\n",
      "    \n",
      "    find_region_bounds(array)\n",
      "        This function finds indices of the extent of the region in\n",
      "        a 2D numpy array. Region must be specified with values greater\n",
      "        than zero.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        array : numpy array\n",
      "                2D numpy array (e.g.: from a raster file)\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        list of int\n",
      "                min_row, max_row, min_col, max_col\n",
      "    \n",
      "    getFeatures(gdf)\n",
      "        Function to parse features from GeoDataFrame\n",
      "        in such a manner that rasterio wants them\n",
      "        https://automating-gis-processes.github.io/CSC18/lessons/L6/clipping-raster.html\n",
      "    \n",
      "    get_lat_lon_coordinates(transform, col, row)\n",
      "        This function gets latitude/North and longitud/East\n",
      "        from set of python array index.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        transform : object\n",
      "                object containing raster properties\n",
      "        col : int\n",
      "                column index\n",
      "        row : int\n",
      "                row index\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        lat, lon : float\n",
      "                coordinates x an y of the array indices col and row\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from DRYP_rrtools import get_lat_lon_coordinates\n",
      "        >>> from DRYP_rrtools import get_transform_parameters\n",
      "        \n",
      "        >>> fname = \"raster.asc\"\n",
      "        >>> crs, transform = get_transform_parameters(fname)\n",
      "        >>> col, row = 20, 30\n",
      "        >>> lat, lon = get_lat_lon_coordinates(transform, col, row)\n",
      "    \n",
      "    get_raster_properties(fname)\n",
      "        This function gets the properties of a raster file.\n",
      "        \n",
      "        \n",
      "        Parameters:\n",
      "        ----------\n",
      "        fname : str\n",
      "                file name of the raster\n",
      "                The raster file should be in a format supported by rasterio (e.g., GeoTIFF).\n",
      "                The raster file should contain the data that you want to extract properties from.\n",
      "                For example, if you have a raster file representing elevation, provide the path to that file.\n",
      "                Make sure to provide the correct file path to the raster file.\n",
      "                Example: \"path/to/raster_file.tif\"\n",
      "        \n",
      "        Returns:\n",
      "        -------\n",
      "        grid_ncols : int\n",
      "                number of columns in the raster file\n",
      "                The number of columns in the raster file.\n",
      "                This value represents the number of pixels along the x-axis of the raster.\n",
      "                Example: 100 (for a raster with 100 columns)\n",
      "                grid_nrows : int\n",
      "                number of rows in the raster file\n",
      "                The number of rows in the raster file.\n",
      "                This value represents the number of pixels along the y-axis of the raster.\n",
      "                Example: 100 (for a raster with 100 rows)\n",
      "                grid_cellsize : float\n",
      "                cell size of the raster file\n",
      "                The cell size of the raster file.\n",
      "                This value represents the size of each pixel in the raster.\n",
      "                Example: 30.0 (for a raster with a cell size of 30 meters)\n",
      "                Note: The cell size is the same for both x and y axes in a square raster.\n",
      "                Make sure to provide the correct cell size for the raster file.\n",
      "    \n",
      "    get_transform_parameters(fname)\n",
      "        This function read a raster file and extract the transformation\n",
      "        parameters. This paramters allows to get the coordinates\n",
      "        (lat/y, lon/x) from indices of a numpy array\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        fname : str\n",
      "                raster file name\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        crs : object\n",
      "                coordinates reference system\n",
      "        transform : 2D numpy array\n",
      "                transformation matrix\n",
      "    \n",
      "    open_raster(fname)\n",
      "        read raster file\n",
      "        Parameters\n",
      "        ----------\n",
      "        fname : str\n",
      "                file name of the raster\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : numpy array\n",
      "                raster values\n",
      "        profile : object\n",
      "                raster properties\n",
      "        transform : object\n",
      "                transformation parameters to pass to other functions\n",
      "    \n",
      "    save_raster(fname, data, profile, transform)\n",
      "        This function saves a raster file with the specified name.\n",
      "        \n",
      "        Parameters:\n",
      "        ----------\n",
      "        fname : str\n",
      "                file name of the raster\n",
      "                The raster file will be created with the specified name.\n",
      "                The raster file will contain the data and properties specified in the profile.\n",
      "                Make sure to provide the correct file path and name for the raster file.\n",
      "                Example: \"path/to/raster_file.tif\"\n",
      "                Note: The raster file will be created in the same format as the input raster file.\n",
      "        \n",
      "        data : numpy array\n",
      "                raster values\n",
      "                The data array contains the raster values that you want to save.\n",
      "                The data array should be a 2D numpy array representing the raster data.\n",
      "                The data array should have the same dimensions as the raster file.\n",
      "                For example, if you have a 100x100 raster, the data array should be of shape (100, 100).\n",
      "                Make sure to provide the correct data array for the raster file.\n",
      "                Example: np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "                Note: The data array should be in the same format as the input raster file.\n",
      "                For example, if the input raster file is in GeoTIFF format, the data array should be in GeoTIFF format.\n",
      "                Make sure to provide the correct data array for the raster file.\n",
      "                \n",
      "        profile : object\n",
      "                raster properties\n",
      "                The profile object contains the metadata and properties of the raster file.\n",
      "                It should be obtained from the input raster file using rasterio.\n",
      "                The profile object should include information such as data type, dimensions, and coordinate reference system.\n",
      "        \n",
      "        \n",
      "        transform : object\n",
      "                transformation parameters\n",
      "                The transform object contains the affine transformation parameters for the raster file.\n",
      "                It should be obtained from the input raster file using rasterio.\n",
      "                The transform object should include information such as pixel size and origin coordinates.\n",
      "        \n",
      "        \n",
      "        Returns:\n",
      "        -------\n",
      "        None\n",
      "                None, but creates a raster file with the specified name.\n",
      "                The raster file will contain the data and properties specified in the profile.\n",
      "                Note: The function does not return any values, but it saves the raster file with the specified name.\n",
      "        \n",
      "        Example:\n",
      "        -------\n",
      "        \n",
      "        >>> fname = \"output_raster.asc\"\n",
      "        >>> data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "        >>> profile = {}\n",
      "        >>> transform = Affine(1, 0, 0, 0, -1, 0)\n",
      "        >>> save_raster(fname, data, profile, transform)\n",
      "        >>> # This will create a raster file named \"output_raster.asc\"\n",
      "        >>> # with the specified data and properties.\n",
      "        >>> # The function does not return any values, but it saves the raster file.\n",
      "    \n",
      "    transform_flowdirection_d8_to_landlab_array(flowdir, format_data='D8')\n",
      "        Function to get flow direction in landlab format from a D8\n",
      "        direction map.\n",
      "        \n",
      "        D8 direction format\n",
      "                32 64 128\n",
      "                16 0  1\n",
      "                8  4  2\n",
      "        \n",
      "        i-digit format 2 -> 8\n",
      "                4 3 2\n",
      "                5 0 1\n",
      "                6 7 8\n",
      "        \n",
      "        Landlab grid\n",
      "                6 7 8\n",
      "                3 4 5\n",
      "                0 1 2\n",
      "        \n",
      "        Parameters:\n",
      "        ----------\n",
      "        flowdir : numpy array of int\n",
      "                flow direction map in D8 format\n",
      "        \n",
      "        Returns:\n",
      "        -------\n",
      "        drinodes: numpy array of ints\n",
      "                flow direction map in landlab format\n",
      "        \n",
      "        Examples:\n",
      "        --------\n",
      "        >>> from DRYP_rrtools import get_landlab_flowdirection_from_d8_format\n",
      "        >>> D8_direction = [            \n",
      "                        [4, 8, 8],\n",
      "                        [4, 3, 8],\n",
      "                        [0, 16, 16],\n",
      "                        ]\n",
      "        \n",
      "        >>> landlab_direction = get_landlab_flowdirection_from_d8_format(D8_direction)\n",
      "        >>> landlab_direction = [\n",
      "                                [3, 3, 4],\n",
      "                                [0, 0, 1],\n",
      "                                [0, 0, 1],\n",
      "                                ]\n",
      "\n",
      "FILE\n",
      "    c:\\users\\edisson\\.conda\\envs\\tdryp\\lib\\site-packages\\cuwalid\\tools\\dryp_rrtools.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(rrtools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calling post processing tool**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the postprocessing tool\n",
    "import cuwalid.tools.DRYP_pptools as pptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module cuwalid.tools.DRYP_pptools in cuwalid.tools:\n",
      "\n",
      "NAME\n",
      "    cuwalid.tools.DRYP_pptools - DRYP: post-processing tools.\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        get_output_filenames\n",
      "        grid_pptools\n",
      "    \n",
      "    class get_output_filenames(builtins.object)\n",
      "     |  get_output_filenames(path_input)\n",
      "     |  \n",
      "     |  Function to get all names of model outputs\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, path_input)\n",
      "     |      Fuction to generate names of model results. This names are\n",
      "     |      paths to the model outputs. The function will read the\n",
      "     |      configuration file and generate the names of the outputs.\n",
      "     |      path_grid : path to the model grid outputs\n",
      "     |      path_csv : path to the model csv outputs\n",
      "     |      path_raster : path to the model raster outputs\n",
      "     |      \n",
      "     |      Parameters:\n",
      "     |      ----------\n",
      "     |      path_input : str\n",
      "     |              filename including path of the model \"input_file\"\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |      --------\n",
      "     |      object containing strings as filenames\n",
      "     |                      \n",
      "     |      Example:\n",
      "     |      --------\n",
      "     |      >>> import DRYP_pptools as pptools\n",
      "     |      >>> fnames = pptools.get_output_filenames(file_model_input)\n",
      "     |      >>> fnames.path_csv\n",
      "     |      >>> fnames.path_csv[\"avg\"]\n",
      "     |      >>> fnames.path_csv[\"point\"][\"pre\"]\n",
      "     |      >>> fnames.path_grid\n",
      "     |      >>> fnames.path_grid[\"grid\"]\n",
      "     |      >>> fnames.path_grid[\"rp\"]\n",
      "     |      >>> fnames.path_raster\n",
      "     |      >>> fnames.path_raster[\"wte\"]\n",
      "     |      >>> fnames.path_raster[\"tht\"]\n",
      "     |      >>> fnames.path_raster[\"Qo\"]\n",
      "     |      >>> fnames.path_raster[\"Vpnd\"]\n",
      "     |      >>> fnames.path_raster[\"thtrp\"]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class grid_pptools(builtins.object)\n",
      "     |  grid_pptools(inputfile)\n",
      "     |  \n",
      "     |  Function to post-processing DRYP model outputs.\n",
      "     |  This function save proccessed variables as netCDF files. \n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import DRYP_pptools as pptools\n",
      "     |  >>> gridpp = pptools.grid_pptools(file_model_input)\n",
      "     |  >>> gridpp.get_mean() # save mean values\n",
      "     |  >>> gridpp.get_wrsi() # save wsri\n",
      "     |  >>> gridpp.get_twsa() # save total water storage anomaly\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, inputfile)\n",
      "     |      Fuction to generate names of model results. This names are\n",
      "     |      then passed to other functions to calculate and save  model\n",
      "     |      results\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inputfile : str\n",
      "     |              filename including path of the model \"input_file\"\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      object containing strings as filenames\n",
      "     |  \n",
      "     |  get_anomalies(self, var_name=None)\n",
      "     |      Get anomalies\n",
      "     |  \n",
      "     |  get_aridity_index(self, var_name=None)\n",
      "     |      Get anomalies\n",
      "     |  \n",
      "     |  get_mean(self, deltat='Y', start_time=None, end_time=None)\n",
      "     |      Thids function get mean values of all variables of a netcdf file\n",
      "     |  \n",
      "     |  get_seasonal_average(self, var_name=None)\n",
      "     |      Get seasonal average values\n",
      "     |  \n",
      "     |  get_twsa(self, var_name=None, mean=True, deltat='Y', start_time=None, end_time=None)\n",
      "     |      Get total water storage anomaly from model outputs\n",
      "     |  \n",
      "     |  get_wrsi(self, deltat='Y', start_time=None, end_time=None)\n",
      "     |      This function gets wrsi index from model outputs\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    calculate_AI_from_netCDF(fname_pre, fname_pet, fname_out=None, deltat='Y', start_time=None, end_time=None, average=True)\n",
      "        Get mean average values from dataset.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        fname : str\n",
      "                file name of the netcdf (from model outputs)\n",
      "        field : list\n",
      "                list of model variables to process\n",
      "        deltat : str\n",
      "                time interval for temporal aggregation.\n",
      "        start_time : str\n",
      "                starting date for the analysis, \"DD-MM-YYYY\".\n",
      "        end_time : str\n",
      "                final date for the analysis, \"DD-MM-YYYY\".\n",
      "        average : bool\n",
      "                if True, the long therm average is caluated otherwise it will\n",
      "                return a time series dataarray\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        netCDF file containing all calculated values\n",
      "    \n",
      "    calculate_WRSI(dataset_aet, dataset_pet)\n",
      "        Calculate Water Requirement Satisfaction Index\n",
      "    \n",
      "    calculate_WRSI_from_netCDF(fname, fname_out=None, deltat='Y', start_time=None, end_time=None)\n",
      "        Get mean average values from dataset.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        fname : str\n",
      "                file name of the netcdf (from model outputs)\n",
      "        field : list\n",
      "                list of model variables to process\n",
      "        deltat : str\n",
      "                time interval for temporal aggregation.\n",
      "        start_time : str\n",
      "                starting date for the analysis, \"DD-MM-YYYY\".\n",
      "        end_time : str\n",
      "                final date for the analysis, \"DD-MM-YYYY\".\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        netCDF file containing all calculated values\n",
      "    \n",
      "    calculate_anomalies_from_netCDF(fname, field='pre', fname_out=None, deltat='Y', start_time=None, end_time=None)\n",
      "        Get anomalies from netcdf filed\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        fname : str\n",
      "                file name of the netcdf (from model outputs)\n",
      "        field : str\n",
      "                model variables to process\n",
      "        deltat : str\n",
      "                time interval for temporal aggregation.\n",
      "        start_time : str\n",
      "                starting date for the analysis, \"DD-MM-YYYY\".\n",
      "        end_time : str\n",
      "                final date for the analysis, \"DD-MM-YYYY\".\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "    \n",
      "    calculate_anomaly(dataset, dataset_mean=None, dim='time')\n",
      "        Calculate anomaly\n",
      "        anomaly = value - mean\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        dataset : DataArray\n",
      "                dataset to calculate the anomaly\n",
      "        dataset_mean : DataArray\n",
      "                mean value\n",
      "        dim : str\n",
      "                name of the axis to calculate mean (defail is \"time\")\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        DataArray\n",
      "                amomalies\n",
      "    \n",
      "    calculate_aridity_index(dataset_pre, dataset_pet)\n",
      "        Calculate the aridity index based on the UNEP:\n",
      "        UNEP. World atlas of desertification - Second Edition. vol. SECOND \n",
      "        EDITION (United Nations Environment Program, 1997)\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        dataset_pre : Dataxarray\n",
      "                precipitation dataset\n",
      "        dataset_pre : Dataxarray\n",
      "                potential evapotranspiration dataset\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        DataArray\n",
      "                Aridity index\n",
      "    \n",
      "    calculate_mean_from_netCDF(fname, field, fname_out=None, deltat='Y', start_time=None, end_time=None)\n",
      "        Get mean average values from dataset. The output filename\n",
      "         will be added \"mean\" at the end of the name.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        fname : str\n",
      "                file name of the netcdf (from model outputs)\n",
      "        field : list\n",
      "                list of model variables to process\n",
      "        deltat : str\n",
      "                time interval for temporal aggregation.\n",
      "        start_time : str\n",
      "                starting date for the analysis, \"DD-MM-YYYY\".\n",
      "        end_time : str\n",
      "                final date for the analysis, \"DD-MM-YYYY\".\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        netCDF file containing all calculated values\n",
      "    \n",
      "    calculate_percentage_anomaly(dataset, dataset_mean=None, offset=None, dim='time')\n",
      "        Calculate anomaly\n",
      "        anomaly = value - mean\n",
      "        If mean value not availble it will calculate the mean values\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        dataset : DataArray\n",
      "                dataset to calculate the anomaly\n",
      "        dataset_mean : DataArray\n",
      "                mean value (optional)\n",
      "        offset : DataArray\n",
      "                offset value to shift mean (optional) \n",
      "        dim : str\n",
      "                name of the axis to calculate mean (defail is \"time\")\n",
      "                \n",
      "        Returns\n",
      "        -------\n",
      "        DataArray\n",
      "                amomalies\n",
      "    \n",
      "    calculate_saturation(dataset, theta_wp, theta_sat)\n",
      "        Calculate the saturation from soil water content, normalization\n",
      "        of water content in relation to saturation\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        dataset : Dataxarray\n",
      "                soil moisture dataset\n",
      "        theta_wp : numpy array\n",
      "                soil moisture at wilting point\n",
      "        theta_sat : numpy array\n",
      "                soil moisture at saturation point (porosity)\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        DataArray\n",
      "                saturation\n",
      "    \n",
      "    calculate_saturation_from_netCDF(fname, path_wp, path_sat, fname_out=None, var_name='tht')\n",
      "        This funtion calculate the saturation from water content from\n",
      "        the dryp model outputs\n",
      "         \n",
      "        Parameters\n",
      "        ----------\n",
      "        fname : str\n",
      "                file name of the netcdf (from model outputs)\n",
      "        path_wp :       str\n",
      "                file name of the wilting point raster dataset\n",
      "        path_sat :      str\n",
      "                file name of the soil moisture at saturation as raster\n",
      "        var_name :      str\n",
      "                model variables to process\n",
      "        deltat : str\n",
      "                time interval for temporal aggregation.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        xarray :\n",
      "                2D time series mean or sum of tne dataset\n",
      "        \n",
      "        Example:\n",
      "        --------\n",
      "        >>> import sys\n",
      "        >>> import os\n",
      "        >>> import geopandas as gpd\n",
      "        \n",
      "        >>> import cuwalid.tools.DRYP_pptools as pptools\n",
      "        \n",
      "        >>>     path_Sy = \"path_to_file\"\n",
      "        >>>     path_surface = \"path_to_file\"\n",
      "        >>>     path_bathymetry = \"path_to_file\"\n",
      "        >>>     path_theta_sat = \"path_to_file\"\n",
      "        >>>     path_theta_wp = \"path_to_file\"\n",
      "        >>>     path_Droot = \"path_to_file\"\n",
      "        \n",
      "        \n",
      "        >>>     fname = \"path_output_netcdf_file\"\n",
      "        >>>     shapefile_path = \"path_output_netcdf_file\"\n",
      "        \n",
      "        >>>     region = gpd.read_file(shapefile_path)\n",
      "        \n",
      "        >>>     pptools.extract_dataset(fname, region, clip_region=False,\n",
      "        >>>             dataPP=None, maskPP=None, bands=[\"pre\", \"aet\", \"rch\", \"dis\"], save=True)\n",
      "        \n",
      "        >>>     pptools.calculate_saturation_from_netCDF(fname, path_theta_wp, path_theta_sat,\n",
      "        >>>                     fname_out=None, var_name=\"tht\")\n",
      "    \n",
      "    calculate_seasonal_average_from_netCDF(fname, var_name='pre', season='OND', fname_out=None, mean=False, start_time=None, end_time=None)\n",
      "        This function calculates the seasonal average from netCDF file\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        fname : str\n",
      "                file name of the netcdf (from model outputs)\n",
      "        var_name :      str\n",
      "                model variables to process\n",
      "        mean : boolean\n",
      "                True calulate the mean, False acculumate over time\n",
      "        deltat : str\n",
      "                time interval for temporal aggregation.\n",
      "        start_time : str\n",
      "                starting date for the analysis, \"DD-MM-YYYY\".\n",
      "        end_time : str\n",
      "                final date for the analysis, \"DD-MM-YYYY\".\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        xarray :\n",
      "                2D time series mean or sum of tne dataset\n",
      "    \n",
      "    calculate_storage(head, theta, surface, bathymetry, bottom, Droot, theta_sat, Sy)\n",
      "        Function to calculate storage for all components of the water balance\n",
      "        calculate the Total storage along the vertical profile of each model cell\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        surface:        surface elevation [m]\n",
      "        bottom:         bottom elevation [m]\n",
      "        bathymetry:     surface elevation of lakes [m] \n",
      "        Droot:          Rooting depth [mm]\n",
      "        theta:          Water content at time t [-]\n",
      "        head:           water table [m]\n",
      "        theta_sat:      Saturated water content [-]\n",
      "        Sy:                     Specific yield [-]\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        total:          Volume of water stored in the saturated zone [mm]\n",
      "    \n",
      "    calculate_storage_from_files(fname, path_surface, path_Droot, path_theta_sat, path_Sy, path_bathymetry=None, path_bottom=None, start_time=None, end_time=None, fname_out=None, anomalies=True)\n",
      "        Calculate storage for all components (surface, subsurface, groundwater)\n",
      "        from model simulations\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        fname : str\n",
      "                file name of the netcdf (from model outputs)\n",
      "        path_surface :  str\n",
      "                file name of raster surface\n",
      "        path_surface :  str\n",
      "                file name of raster surface\n",
      "        path_bathymetry :       str\n",
      "                file name of raster surface\n",
      "        path_bottom :   str\n",
      "                file name of raster surface\n",
      "        path_Droot :    str\n",
      "                file name of raster surface\n",
      "        path_theta_sat :        str\n",
      "                file name of raster surface\n",
      "        path_Sy :       str\n",
      "                file name of raster surface\n",
      "        start_time : str\n",
      "                starting date for the analysis, \"DD-MM-YYYY\".\n",
      "        end_time : str\n",
      "                final date for the analysis, \"DD-MM-YYYY\".\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "    \n",
      "    calculate_twsa_from_netCDF(fname, fname_out=None, var_name='twsc', start_time=None, end_time=None)\n",
      "        This funtion calculate the total water storage anomaly\n",
      "         from the dryp model outputs\n",
      "         \n",
      "        Parameters\n",
      "        ----------\n",
      "        fname : str\n",
      "                file name of the netcdf (from model outputs)\n",
      "        var_name :      str\n",
      "                model variables to process\n",
      "        mean : boolean\n",
      "                True calulate the mean, False acculumate over time\n",
      "        deltat : str\n",
      "                time interval for temporal aggregation.\n",
      "        start_time : str\n",
      "                starting date for the analysis, \"DD-MM-YYYY\".\n",
      "        end_time : str\n",
      "                final date for the analysis, \"DD-MM-YYYY\".\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        xarray :\n",
      "                2D time series mean or sum of tne dataset\n",
      "    \n",
      "    calculate_weighted_stats_dataset(dataset, weight=None, dim='sim')\n",
      "        This function calculate the weighted mean and standard deviation\n",
      "        of dataset\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        dataset : DataArray\n",
      "                dataset to calculate the anomaly\n",
      "        dataset_mean : DataArray\n",
      "                mean value (optional)\n",
      "        offset : DataArray\n",
      "                offset value to shift mean (optional) \n",
      "        dim : str\n",
      "                name of the axis to calculate mean (defail is \"time\")\n",
      "                \n",
      "        Returns\n",
      "        -------\n",
      "        DataArray\n",
      "                amomalies\n",
      "    \n",
      "    check_if_field_available_in_netCDF(fname, var_name)\n",
      "        This function check it a variable is stored in the netCDF file\n",
      "    \n",
      "    clip_dataset_by_region(ds, region)\n",
      "        This function clip netcdf files by region, projection should\n",
      "        match WGS84, otherwise it will raise an error.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        dataset : data xarray\n",
      "                dataset\n",
      "        region : geodataframe\n",
      "                name of variable to process\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        dataset : xarray dataset\n",
      "    \n",
      "    create_ensamble_simulations(fname_list, var_name='tht')\n",
      "        This function create an ensamble of simulations. This function\n",
      "        aggregate the datasets to the specified time step and calculate\n",
      "        the mean values\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        fname_list : list\n",
      "                list of paths of model output files\n",
      "        var_name : str\n",
      "                variable to process\n",
      "                \n",
      "        Returns\n",
      "        -------\n",
      "        DataArray\n",
      "                ensable of multiple simulations\n",
      "    \n",
      "    extract_dataset(netcdf_path, region, clip_region=True, dataPP=None, maskPP=None, fname_out=None, save=False, bands=['pre'])\n",
      "        This function clip netcdf files by region, projection should\n",
      "        match WGS84, otherwise it will raise an error.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        netcdf_path : str\n",
      "                list of paths\n",
      "        region : geodataframe\n",
      "                name of variable to process\n",
      "        region_clip: bool\n",
      "                make values outside the region NaN, default true\n",
      "        save: bool\n",
      "                activate save option, default true\n",
      "        fname_out : str\n",
      "                path of outputs\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        dataset : xarray dataset\n",
      "                concatenated datasets\n",
      "        \n",
      "        Example:\n",
      "        --------\n",
      "        >>> import geopandas as gpd\n",
      "        >>> import cuwalid.tools.DRYP_pptools as pptools\n",
      "        \n",
      "        >>>     fname = \"path_output_netcdf_file\"\n",
      "        >>>     shapefile_path = \"path_output_netcdf_file\"\n",
      "        \n",
      "        >>>     region = gpd.read_file(shapefile_path)\n",
      "        \n",
      "        >>>     pptools.extract_dataset(fname, region, clip_region=False,\n",
      "        >>>             dataPP=None, maskPP=None, bands=[\"pre\", \"aet\", \"rch\", \"dis\"], save=True)\n",
      "    \n",
      "    get_dataframe_point_from_netcdf(fname, fname_csv, field='dis', xlabel='East', ylabel='North')\n",
      "        get point values along the time axis of a specified netcdf file at\n",
      "        coordinets specifed in a csv file.\n",
      "        \n",
      "        Parameters\n",
      "        -----------\n",
      "        fname : str\n",
      "                path of netcdf file\n",
      "        fname_csv : str\n",
      "                path of csv file containing point\n",
      "        field : str\n",
      "                name of the field to get values (default: dis)\n",
      "        xlabel : str\n",
      "                name of the head of the x coordinates, default is East\n",
      "        ylabel : str\n",
      "                name of the head of the y coordinates, default is North\n",
      "                \n",
      "        Returns\n",
      "        -------\n",
      "        dataframe\n",
      "    \n",
      "    get_dataframe_zone_from_netcdf(fname, fname_mask, field=['twsc'], regionid=None)\n",
      "        Caclulate the mean values of zone from a netcdf and store it as\n",
      "        dataframe\n",
      "        \n",
      "        Parameters\n",
      "        -----------\n",
      "        fname : str\n",
      "                path of netcdf file\n",
      "        mask : bo\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        dataframe\n",
      "    \n",
      "    get_ensamble_from_netcdf_list(fname_list, var_name, mean=True, save=True, fname_output=None)\n",
      "        This function read a list of netcdf paths and return a dataset\n",
      "        or netCDF file containing all netCDFs\n",
      "    \n",
      "    get_month_first_letter(month_number)\n",
      "    \n",
      "    get_point_from_dataset(dataset, x_coord, y_coord, field)\n",
      "        Get time series of a point from a netCDF\n",
      "        \n",
      "        Parameters:\n",
      "        ----------\n",
      "        dataset : dataset\n",
      "                dataset from which the mean will be extracted\n",
      "        x_coord : list\n",
      "                x coordinates of the points\n",
      "        y_coord : list\n",
      "                y coordinates of the points\n",
      "        field : list\n",
      "                name of the field to get values (default: dis)\n",
      "        \n",
      "        \n",
      "        Returns:\n",
      "        -------\n",
      "                dataframe\n",
      "                containing the time series of the points\n",
      "        \n",
      "        Example:\n",
      "        --------\n",
      "        >>> import cuwalid.tools.DRYP_pptools as pptools\n",
      "        >>> import pandas as pd\n",
      "        >>> import xarray as xr\n",
      "        >>> import os\n",
      "        >>> import numpy as np\n",
      "        >>> import rasterio\n",
      "    \n",
      "    get_season_name(season)\n",
      "    \n",
      "    get_zone_from_dataset(dataset, mask)\n",
      "        Get time series of a zone from a netCDF\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        dataset : dataset\n",
      "                dataset from which the mean will be extracted\n",
      "        mask : boolean array\n",
      "                masked array\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        numpy array\n",
      "    \n",
      "    merge_xarray_dataset(dataset1, dataset2)\n",
      "    \n",
      "    preprocesses_netCDF(fname, var_name, mean=True, deltat='Y', start_time=None, end_time=None)\n",
      "        This function read, slice, and resample netCDF files.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        fname : str\n",
      "                file name of the netcdf (from model outputs)\n",
      "        var_name :      str\n",
      "                model variables to process\n",
      "        mean : boolean\n",
      "                True calulate the mean, False acculumate over time\n",
      "        deltat : str\n",
      "                time interval for temporal aggregation.\n",
      "        start_time : str\n",
      "                starting date for the analysis, \"DD-MM-YYYY\".\n",
      "        end_time : str\n",
      "                final date for the analysis, \"DD-MM-YYYY\".\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        xarray :\n",
      "                2D time series mean or sum of tne dataset\n",
      "    \n",
      "    read_dataset(fname, var_name='tht')\n",
      "    \n",
      "    reproject_dataset(data, oldPP, newPP)\n",
      "        Transform projection system\n",
      "        oldPP and newPP have to be defined first\n",
      "        \n",
      "        Parameters:\n",
      "        ----------\n",
      "        Data:   Dataset\n",
      "                dataset to be reprojected\n",
      "        oldPP:  Projection\n",
      "                projection of the dataset\n",
      "        newPP:  Projection\n",
      "                projection of the new dataset\n",
      "        \n",
      "        Returns:\n",
      "        -------\n",
      "        Data:   Dataset\n",
      "                reprojected dataset\n",
      "                \n",
      "        Example:\n",
      "        >>> import cuwalid.tools.DRYP_pptools as pptools\n",
      "        >>> import pandas as pd\n",
      "        >>> import xarray as xr\n",
      "        >>> import os\n",
      "    \n",
      "    resample_dataset(data, mean=True, deltat='Y')\n",
      "    \n",
      "    save_xarray_dataset_as_netcdf(fname, data, var_name)\n",
      "    \n",
      "    season_name_to_number(season)\n",
      "        Converts a string representing a season to a list of numbers indicating corresponding months.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        season : str or list or int\n",
      "            The season represented by three capital letters (e.g., \"OND\") or a list of month numbers.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        list\n",
      "            A list of integers representing the months for the given season. If the input is already \n",
      "            a list of months, it is returned as is. If the input is not recognized, it returns \n",
      "            the input wrapped in a list.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Supported season codes:\n",
      "        - \"MAM\" : March, April, May [3, 4, 5]\n",
      "        - \"OND\" : October, November, December [10, 11, 12]\n",
      "        - \"JJS\" : June, July, August [6, 7, 8]\n",
      "        - \"JF\"  : January, February [1, 2]\n",
      "        - \"JJSA\": June, July, August, September [6, 7, 8, 9]\n",
      "        \n",
      "        If the input is not a string or a list, the function wraps the input in a list.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> season_name_to_number(\"MAM\")\n",
      "        [3, 4, 5]\n",
      "        \n",
      "        >>> season_name_to_number([1, 2, 3])\n",
      "        [1, 2, 3]\n",
      "        \n",
      "        >>> season_name_to_number(2)\n",
      "        [2]\n",
      "    \n",
      "    slice_dataset_time(dataset, start_time=None, end_time=None)\n",
      "\n",
      "FILE\n",
      "    c:\\users\\edisson\\.conda\\envs\\tdryp\\lib\\site-packages\\cuwalid\\tools\\dryp_pptools.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pptools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
